{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning in Audio Classification in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import python_speech_features\n",
    "from python_speech_features import mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dropout, Dense\n",
    "from keras.layers import LSTM, TimeDistributed\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, mode= 'conv', nfilt=26, nfeat=13, nfft = 2048, rate = 16000):\n",
    "        self.mode = mode\n",
    "        self.nfilt = nfilt\n",
    "        self.nfeat = nfeat\n",
    "        self.nfft = nfft\n",
    "        self.rate = rate\n",
    "        self.step = int(rate/10)\n",
    "        self.model_path = os.path.join('models', mode + '.model')\n",
    "        self.p_path = os.path.join('pickles', mode + '.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data():\n",
    "    if os.path.isfile(config.p_path):\n",
    "        print('Loading existing data for {} model'.format(config.mode))\n",
    "        with open(config.p_path, 'rb') as handle:\n",
    "            tmp = pickle.load(handle)\n",
    "            return tmp\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rand_feat():\n",
    "    tmp = check_data()\n",
    "    if tmp:\n",
    "        return tmp.data[0], tmp.data[1]\n",
    "        \n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    _min, _max = float('inf'), -float('inf')\n",
    "    \n",
    "    for _ in tqdm(range(n_samples)):\n",
    "        \n",
    "        rand_class = np.random.choice(class_dist.index, p = prob_dist)\n",
    "        \n",
    "        file = np.random.choice(df[df.Class==rand_class].index)\n",
    "        \n",
    "        rate, wav = wavfile.read(dataset_directory+str(rand_class)+\"/\"+str(file))\n",
    "        Class = df.at[file, 'Class']\n",
    "        \n",
    "        rand_index = np.random.randint(0, wav.shape[0]-config.step)\n",
    "        \n",
    "        sample = wav[rand_index : rand_index + config.step]\n",
    "        X_sample = mfcc(sample, rate, numcep=config.nfeat, nfilt=config.nfilt, nfft=config.nfft)\n",
    "        \n",
    "        _min = min(np.amin(X_sample), _min)\n",
    "        _max = max(np.amax(X_sample), _max)\n",
    "        \n",
    "        X.append(X_sample)\n",
    "        y.append(classes.index(Class))\n",
    "        \n",
    "    \n",
    "    config.min = _min\n",
    "    config.max = _max\n",
    "    \n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = (X- _min) / (_max - _min)\n",
    "    \n",
    "    if config.mode == 'conv':\n",
    "        X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "    elif config.mode =='time':\n",
    "        X = X.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
    "    \n",
    "    y = to_categorical(y, num_classes=2)\n",
    "    \n",
    "    config.data = (X, y)\n",
    "    \n",
    "    with open(config.p_path, 'wb') as handle:\n",
    "        pickle.dump(config, handle, protocol=2)\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reccurent_model():\n",
    "    ### Shape of data for RNN is (n, time, freq)\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(128, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense(64, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(32, activation='relu')))\n",
    "    model.add(TimeDistributed(Dense(16, activation='relu')))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('Temp_Dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(os.listdir('Dataset/train/'))\n",
    "\n",
    "print(\"Number of Classes in the Data Set:\", len(classes), \"Classes\")\n",
    "print(\"The classes of the dataset are   :\", classes[0], \",\", classes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['Fname','Class', 'Length']\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_directory = 'Dataset/Train/'\n",
    "dataset_directory = 'Temp_Dataset/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in list(classes):\n",
    "    print('Number of files in the directory \\'{}\\' are {}'.format(c,len(os.listdir(dataset_directory+c))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in list(classes):\n",
    "    for n,f in tqdm(enumerate(os.listdir(dataset_directory+c))):\n",
    "        rate, signal = wavfile.read(dataset_directory+str(c)+\"/\"+str(f))\n",
    "        length = signal.shape[0]/rate\n",
    "        f_df = pd.DataFrame({\n",
    "            \"Fname\": str(f),\n",
    "            \"Class\": str(c),\n",
    "            \"Length\": length}, index = [n])\n",
    "        df = df.append(f_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dist = df.groupby(['Class'])['Length'].mean()\n",
    "class_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Fname', inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2 * int(df['Length'].sum()/0.1)\n",
    "prob_dist = class_dist / class_dist.sum()\n",
    "choices = np.random.choice(class_dist.index, p= prob_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(mode = 'time')\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = build_rand_feat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_flat = np.argmax(y, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X.shape[1], X.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = get_reccurent_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(config.model_path, monitor='val_acc', verbose=1, mode='max',\n",
    "                            save_best_only=True, save_weights_only=False, period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X, y, epochs=250, batch_size=32, shuffle = True, validation_split=0.1, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, sharex=False, sharey=True, figsize=(20,8))\n",
    "\n",
    "# Plot accuracy per iteration\n",
    "plt.plot(model.history.history['acc'][:50], label='acc')\n",
    "plt.plot(model.history.history['val_acc'][:50], label='val_acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.title('Custom Built LSTM RNN Model\\'s Training Analysis on the sickness and non-sickness Audio Data', size=16)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"accuracy reached\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
